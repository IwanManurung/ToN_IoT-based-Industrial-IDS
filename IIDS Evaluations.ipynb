{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea1f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: A restricted method in java.lang.System has been called\n",
      "WARNING: java.lang.System::load has been called by org.jpype.JPypeContext in an unnamed module (file:/Users/iwan/Attraction/Venture/p3apps/.venv/lib/python3.12/site-packages/org.jpype.jar)\n",
      "WARNING: Use --enable-native-access=ALL-UNNAMED to avoid a warning for callers in this module\n",
      "WARNING: Restricted methods will be blocked in a future release unless native access is enabled\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from src import iids_util\n",
    "from sklearn.metrics import (cohen_kappa_score)\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bfe3c8",
   "metadata": {},
   "source": [
    "### Evaluating IIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f00ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluator(scenario, layer ,dev, target_class):\n",
    "    key = f\"output/{layer.title()}-IIDS_S{scenario}_{dev}_{target_class}.json\"\n",
    "    with open(key, 'r') as f:\n",
    "        metric = json.load(f)\n",
    "    del key\n",
    "    key = f\"output/{layer.title()}-IIDS_S{scenario}_{dev}_{target_class}.csv\"\n",
    "    output = pd.read_csv(key, low_memory=False)\n",
    "    return (output, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1892a87",
   "metadata": {},
   "source": [
    "### Decision's Reliability\n",
    "1. Agreement score between Edge-IIDS and Fog-IIDS\n",
    "2. Agreement score inter-model in an IIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37e995d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario-1\n",
    "scenario = 3\n",
    "e_out, e_met = get_evaluator(scenario=scenario, layer='edge', dev='fridge', target_class='normal')\n",
    "f_out, f_met = get_evaluator(scenario=scenario, layer='fog', dev='fridge', target_class='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dd92a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrement Score Edge-IIDS vs Fog-IIDS:  0.611\n"
     ]
    }
   ],
   "source": [
    "# Agreement Score between Edge-IIDS and Fog-IIDS\n",
    "agg_score = cohen_kappa_score(y1=e_out['y_predict'].tolist(),\n",
    "                              y2=f_out['y_predict'].tolist())\n",
    "print(\"Aggrement Score Edge-IIDS vs Fog-IIDS: \", f'{agg_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d60a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-Model in Edge-IIDS\n",
    "learner = e_out.drop(columns=['y_predict', 'y_true']).columns.tolist()\n",
    "scores = e_out[learner].to_numpy()\n",
    "preds = [iids_util.proba_prediction_rules(nscore=i) for i in scores]\n",
    "yname = [f'y{num}' for num in range(1, len(learner)+1)]\n",
    "e_out[yname] = preds\n",
    "del scores, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a129190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score y1 vs y2: -0.43\n",
      "Agreement score y1 vs y3: -0.55\n",
      "Agreement score y1 vs y4: -0.15\n",
      "Agreement score y1 vs y5: -0.23\n",
      "Agreement score y1 vs y6: -0.26\n",
      "Agreement score y2 vs y3: 0.39\n",
      "Agreement score y2 vs y4: 0.07\n",
      "Agreement score y2 vs y5: 0.09\n",
      "Agreement score y2 vs y6: 0.05\n",
      "Agreement score y3 vs y4: 0.05\n",
      "Agreement score y3 vs y5: 0.10\n",
      "Agreement score y3 vs y6: 0.12\n",
      "Agreement score y4 vs y5: 0.69\n",
      "Agreement score y4 vs y6: 0.73\n",
      "Agreement score y5 vs y6: 0.77\n"
     ]
    }
   ],
   "source": [
    "for pair in combinations(yname, 2):\n",
    "    score = cohen_kappa_score(y1=e_out[pair[0]].tolist(),\n",
    "                              y2=e_out[pair[1]].tolist())\n",
    "    msg = f'Agreement score {pair[0]} vs {pair[1]}: {score:.2f}'\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da1815be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-Model in Fog-IIDS\n",
    "learner = f_out.drop(columns=['y_predict', 'y_true']).columns.tolist()\n",
    "scores = f_out[learner].to_numpy()\n",
    "preds = [iids_util.proba_prediction_rules(nscore=i) for i in scores]\n",
    "yname = [f'y{num}' for num in range(1, len(learner)+1)]\n",
    "f_out[yname] = preds\n",
    "del scores, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa764fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement score y1 vs y2: 0.89\n",
      "Agreement score y1 vs y3: 0.92\n",
      "Agreement score y2 vs y3: 0.91\n"
     ]
    }
   ],
   "source": [
    "for pair in combinations(yname, 2):\n",
    "    score = cohen_kappa_score(y1=f_out[pair[0]].tolist(),\n",
    "                              y2=f_out[pair[1]].tolist())\n",
    "    msg = f'Agreement score {pair[0]} vs {pair[1]}: {score:.2f}'\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
